{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Networks\n",
    "\n",
    "In theory, very deep networks can represent very complex functions; but in practice, they are hard to train. Residual Networks, introduced by He et al., allow you to train much deeper networks than were previously practically feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from resnets_utils import *\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import h5py\n",
    "import json\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem of very deep neural networks\n",
    "\n",
    "The main benefit of a very deep network is that it can represent very complex functions. It can also learn features at many different levels of abstraction, from edges (at the lower layers) to very complex features (at the deeper layers). However, using a deeper network doesn't always help. A huge barrier to training them is vanishing gradients: very deep networks often have a gradient signal that goes to zero quickly, thus making gradient descent unbearably slow. More specifically, during gradient descent, as you backprop from the final layer back to the first layer, you are multiplying by the weight matrix on each step, and thus the gradient can decrease exponentially quickly to zero (or, in rare cases, grow exponentially quickly and \"explode\" to take very large values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Residual Network\n",
    "\n",
    "In ResNets, a \"shortcut\" or a \"skip connection\" allows the gradient to be directly backpropagated to earlier layers.\n",
    "\n",
    "Having ResNet blocks with the shortcut also makes it very easy for one of the blocks to learn an identity function. This means that you can stack on additional ResNet blocks with little risk of harming training set performance. (There is also some evidence that the ease of learning an identity function--even more than skip connections helping with vanishing gradients--accounts for ResNets' remarkable performance.)\n",
    "\n",
    "Two main types of blocks are used in a ResNet, depending mainly on whether the input/output dimensions are same or different.\n",
    "\n",
    "    -> The identity block\n",
    "\n",
    "The identity block is the standard block used in ResNets, and corresponds to the case where the input activation (say $a^{[l]}$) has the same dimension as the output activation (say $z^{[l+2]}$). In other words, the shape of $z^{[l+2]}$ is\n",
    "matched to that of $a^{[l]}$ using a (1,1) convolution(to match the depth/channels).\n",
    "    \n",
    "    -> The Convolutional block\n",
    "    \n",
    "This type of block is used when the input and output dimensions don't match up. The difference with the identity block is that there is a CONV2D layer in the shortcut path. CONV2D layer in the shortcut path is used to resize the input $a^{[l]}$ \n",
    "to a different dimension, so that the dimensions match up in the final addition to $z^{[l+2]}$, needed to add the shortcut \n",
    "value back to the main path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block with skip connection over 3 layers, a[l] to z[l+3]\n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First Component - Conv (1,1) + BN along channels + ReLU\n",
    "    X = keras.layers.Conv2D(filters=F1, \n",
    "                            kernel_size=(1,1), \n",
    "                            strides=(1,1), \n",
    "                            padding='same', \n",
    "                            name=conv_name_base+'2a', \n",
    "                            kernel_initializer=glorot_uniform(seed=0)\n",
    "                           )(X)\n",
    "    X = keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2a')(X)\n",
    "    X = keras.layers.Activation(activation='relu')(X)\n",
    "    \n",
    "    # Second Component - Conv (f,f) + BN along channels + ReLU\n",
    "    X = keras.layers.Conv2D(filters=F2, \n",
    "                            kernel_size=(f,f), \n",
    "                            strides=(1,1), \n",
    "                            padding='same', \n",
    "                            name=conv_name_base+'2b', \n",
    "                            kernel_initializer=glorot_uniform(seed=0)\n",
    "                           )(X)\n",
    "    X = keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2b')(X)\n",
    "    X = keras.layers.Activation(activation='relu')(X)\n",
    "    \n",
    "    # Third Component - Conv (1,1) + BN along channels + add shortcut(residual) + ReLU\n",
    "    X = keras.layers.Conv2D(filters=F3, \n",
    "                            kernel_size=(1,1), \n",
    "                            strides=(1,1), \n",
    "                            padding='same', \n",
    "                            name=conv_name_base+'2c', \n",
    "                            kernel_initializer=glorot_uniform(seed=0)\n",
    "                           )(X)\n",
    "    X = keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2c')(X)\n",
    "    #assert(X.shape == X_shortcut.shape) # Shape matches up in identity block\n",
    "    X = keras.layers.Add()([X, X_shortcut])\n",
    "    X = keras.layers.Activation(activation='relu')(X)\n",
    "    \n",
    "    return X  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [0.94822985 0.         1.1610144  2.747859   0.         1.36677   ]\n",
      "Shape of output: (3, 4, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    A = identity_block(A_prev, f=2, filters=[2, 4, 6], stage=1, block='a')\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))\n",
    "    print(\"Shape of output: \" + str(out[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s=1):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block  with skip connection over 3 layers, a[l] to z[l+3] and \n",
    "    Conv2D in the shortcut path to match the shapes of a[l] and z[l+3] during addition\n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First Component - Conv (1,1) and stride(s,s) + BN along channels + ReLU\n",
    "    X = keras.layers.Conv2D(filters=F1, \n",
    "                            kernel_size=(1,1), \n",
    "                            strides=(s,s),\n",
    "                            padding='same',\n",
    "                            name=conv_name_base+'2a', \n",
    "                            kernel_initializer=glorot_uniform(seed=0)\n",
    "                           )(X)\n",
    "    #print('I: '+str(X.shape))\n",
    "    X = keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2a')(X)\n",
    "    X = keras.layers.Activation(activation='relu')(X)\n",
    "    \n",
    "    # Second Component - Conv (f,f) + BN along channels + ReLU\n",
    "    X = keras.layers.Conv2D(filters=F2, \n",
    "                            kernel_size=(f,f), \n",
    "                            strides=(1,1), \n",
    "                            padding='same', \n",
    "                            name=conv_name_base+'2b', \n",
    "                            kernel_initializer=glorot_uniform(seed=0)\n",
    "                           )(X)\n",
    "    #print('II: '+str(X.shape))\n",
    "    X = keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2b')(X)\n",
    "    X = keras.layers.Activation(activation='relu')(X)\n",
    "    \n",
    "    # Third Component part I - Conv (1,1) + BN along channels\n",
    "    X = keras.layers.Conv2D(filters=F3, \n",
    "                            kernel_size=(1,1), \n",
    "                            strides=(1,1), \n",
    "                            padding='same', \n",
    "                            name=conv_name_base+'2c', \n",
    "                            kernel_initializer=glorot_uniform(seed=0)\n",
    "                           )(X)\n",
    "    #print('III: '+str(X.shape))\n",
    "    X = keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2c')(X)\n",
    "    \n",
    "    # Shortcut Component - F3 Conv (1,1) filters and stride(s,s) + BN along channels\n",
    "    X_shortcut = keras.layers.Conv2D(filters=F3, \n",
    "                                     kernel_size=(1,1), \n",
    "                                     strides=(s,s),\n",
    "                                     padding='same',\n",
    "                                     name=conv_name_base+'1', \n",
    "                                     kernel_initializer=glorot_uniform(seed=0)\n",
    "                                    )(X_shortcut)\n",
    "    X_shortcut = keras.layers.BatchNormalization(axis=3, name=bn_name_base+'1')(X_shortcut)\n",
    "    \n",
    "    # Third Component part II - Add layer(main and shortcut) + ReLU\n",
    "    #print(\"X: \" + str(X.shape))\n",
    "    #print(\"X_shortcut: \" + str(X_shortcut.shape))\n",
    "    #assert(X.shape == X_shortcut.shape)\n",
    "    X = keras.layers.Add()([X, X_shortcut])\n",
    "    X = keras.layers.Activation(activation='relu')(X)\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of output: (3, 4, 4, 6)\n",
      "out = [0.14074254 1.2335387  0.         0.19140035 0.75703484 0.4619543 ]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    A = convolutional_block(A_prev, f=2, filters=[2, 4, 6], stage=1, block='a')\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "    print(\"Shape of output: \" + str(out[0].shape))\n",
    "    print(\"out = \" + str(out[0][1][1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building ResNet - 50\n",
    "\n",
    "The details of this ResNet-50 model are:\n",
    "- Zero-padding pads the input with a pad of (3,3)\n",
    "- Stage 1:\n",
    "    - The 2D Convolution has 64 filters of shape (7,7) and uses a stride of (2,2). Its name is \"conv1\".\n",
    "    - BatchNorm is applied to the channels axis of the input.\n",
    "    - MaxPooling uses a (3,3) window and a (2,2) stride.\n",
    "- Stage 2:\n",
    "    - The convolutional block uses three set of filters of size [64,64,256], \"f\" is 3, \"s\" is 1 and the block is \"a\".\n",
    "    - The 2 identity blocks use three set of filters of size [64,64,256], \"f\" is 3 and the blocks are \"b\" and \"c\".\n",
    "- Stage 3:\n",
    "    - The convolutional block uses three set of filters of size [128,128,512], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
    "    - The 3 identity blocks use three set of filters of size [128,128,512], \"f\" is 3 and the blocks are \"b\", \"c\" and \"d\".\n",
    "- Stage 4:\n",
    "    - The convolutional block uses three set of filters of size [256, 256, 1024], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
    "    - The 5 identity blocks use three set of filters of size [256, 256, 1024], \"f\" is 3 and the blocks are \"b\", \"c\", \"d\", \"e\" and \"f\".\n",
    "- Stage 5:\n",
    "    - The convolutional block uses three set of filters of size [512, 512, 2048], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
    "    - The 2 identity blocks use three set of filters of size [512, 512, 2048], \"f\" is 3 and the blocks are \"b\" and \"c\".\n",
    "- The 2D Average Pooling uses a window of shape (2,2) and its name is \"avg_pool\".\n",
    "- The flatten doesn't have any hyperparameters or name.\n",
    "- The Fully Connected (Dense) layer reduces its input to the number of classes using a softmax activation. Its name should be `'fc' + str(classes)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(64, 64, 3), n_classes=6):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    n_classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a input layer\n",
    "    X_input = keras.layers.Input(input_shape)\n",
    "    \n",
    "    # Zeropadding (3,3)\n",
    "    X = keras.layers.ZeroPadding2D((3,3))(X_input)\n",
    "    \n",
    "    # Stage I: 64 Conv2D (7,7) filters stride(2,2) + BN along channels + MaxPool (3,3) stride(2,2)\n",
    "    X = keras.layers.Conv2D(filters=64, \n",
    "                            kernel_size=(7,7), \n",
    "                            strides=(2,2), \n",
    "                            name='conv1', \n",
    "                            kernel_initializer=glorot_uniform(seed=0)\n",
    "                           )(X)\n",
    "    X = keras.layers.BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(X)\n",
    "    \n",
    "    # Stage II: Conv Block [64,64,256] + 2* Identity Blocks [64,64,256]\n",
    "    X = convolutional_block(X=X, f=3, filters=[64,64,256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X=X, f=3, filters=[64,64,256], stage=2, block='b')\n",
    "    X = identity_block(X=X, f=3, filters=[64,64,256], stage=2, block='c')\n",
    "    \n",
    "    # Stage III: Conv Block [128,128,512] + 3* Identity Blocks [128,128,512]\n",
    "    X = convolutional_block(X=X, f=3, filters=[128,128,512], stage=3, block='a', s=2)\n",
    "    X = identity_block(X=X, f=3, filters=[128,128,512], stage=3, block='b')\n",
    "    X = identity_block(X=X, f=3, filters=[128,128,512], stage=3, block='c')\n",
    "    X = identity_block(X=X, f=3, filters=[128,128,512], stage=3, block='d')\n",
    "    \n",
    "    # Stage IV: Conv Block [256,256,1024] + 5* Identity Blocks[256,256,1024]\n",
    "    X = convolutional_block(X=X, f=3, filters=[256,256,1024], stage=4, block='a', s=2)\n",
    "    X = identity_block(X=X, f=3, filters=[256,256,1024], stage=4, block='b')\n",
    "    X = identity_block(X=X, f=3, filters=[256,256,1024], stage=4, block='c')\n",
    "    X = identity_block(X=X, f=3, filters=[256,256,1024], stage=4, block='d')\n",
    "    X = identity_block(X=X, f=3, filters=[256,256,1024], stage=4, block='e')\n",
    "    X = identity_block(X=X, f=3, filters=[256,256,1024], stage=4, block='f')\n",
    "    \n",
    "    # Stage V: Conv Block [512,512,2014] + 2* Identity Blocks[512,512,2048]\n",
    "    X = convolutional_block(X=X, f=3, filters=[512,512,2048], stage=5, block='a', s=2)\n",
    "    X = identity_block(X=X, f=3, filters=[512,512,2048], stage=5, block='b')\n",
    "    X = identity_block(X=X, f=3, filters=[512,512,2048], stage=5, block='c')\n",
    "    \n",
    "    # Average Pooling\n",
    "    X = keras.layers.AveragePooling2D(pool_size=(2,2))(X)\n",
    "    \n",
    "    # Flatten\n",
    "    X = keras.layers.Flatten()(X)\n",
    "    \n",
    "    # Fully Connected Layer with softmax and n_classes units\n",
    "    X = keras.layers.Dense(units=n_classes, \n",
    "                           activation='softmax', \n",
    "                           name='fc'+str(n_classes), \n",
    "                           kernel_initializer=glorot_uniform(seed=0)\n",
    "                          )(X)\n",
    "    \n",
    "    # Create an object of Model class from keras.models and pass the input and output\n",
    "    model = keras.models.Model(inputs=X_input, outputs=X, name='resnet50')\n",
    "    \n",
    "    return model   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ResNet50 model object\n",
    "\n",
    "model = ResNet50(input_shape=(64, 64, 3), n_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with adam optimizer, categorical crossentropy loss and accuracy as metrics\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the signs dataset\n",
    "\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig / 255.\n",
    "X_test = X_test_orig / 255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1080/1080 [==============================] - 305s 282ms/step - loss: 0.6120 - acc: 0.8954\n",
      "Epoch 2/3\n",
      "1080/1080 [==============================] - 291s 270ms/step - loss: 0.6376 - acc: 0.8954\n",
      "Epoch 3/3\n",
      "1080/1080 [==============================] - 311s 288ms/step - loss: 0.4519 - acc: 0.9481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fc430297f0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Training of 25 epochs(warning it's a DEEP model and will take 5 to 6 minutes per epoch on CPU)\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = 25, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "\n",
    "model.save(\"ResNet50_hand_signs_25ep.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 17s 145ms/step\n",
      "Loss = 0.45328784386316934\n",
      "Test Accuracy = 0.874999996026357\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = load_model(\"ResNet50_hand_signs_25ep.h5\")\n",
    "\n",
    "# Make predictions\n",
    "preds = model.evaluate(X_test, Y_test)\n",
    "print(\"Loss = \" + str(preds[0]))\n",
    "print(\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 70, 70, 3)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 32, 64)   9472        zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 32, 32, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 15, 15, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 15, 15, 64)   4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 15, 15, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 15, 15, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 15, 15, 64)   36928       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 15, 15, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 15, 15, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 15, 15, 256)  16640       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 15, 15, 256)  16640       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 15, 15, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 15, 15, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 15, 15, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 15, 15, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 15, 15, 64)   16448       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 15, 15, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 15, 15, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 15, 15, 64)   36928       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 15, 15, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 15, 15, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 15, 15, 256)  16640       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 15, 15, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 15, 15, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 15, 15, 256)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 15, 15, 64)   16448       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 15, 15, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 15, 15, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 15, 15, 64)   36928       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 15, 15, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 15, 15, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 15, 15, 256)  16640       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 15, 15, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 15, 15, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 15, 15, 256)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 8, 8, 128)    32896       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 128)    0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 128)    0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 8, 8, 512)    131584      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 8, 8, 512)    2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 8, 8, 512)    0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 512)    0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 128)    0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 8, 8, 128)    0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 8, 8, 512)    0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 8, 8, 512)    0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 8, 8, 128)    0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 128)    0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 8, 8, 512)    0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 512)    0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 128)    0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 128)    0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 8, 8, 512)    0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 512)    0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 4, 4, 256)    131328      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 4, 4, 1024)   525312      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 4, 4, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 4, 4, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 4, 4, 1024)   0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 4, 4, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 4, 4, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 4, 4, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 4, 4, 1024)   0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 4, 4, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 4, 4, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 4, 4, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 4, 4, 1024)   0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 4, 4, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 4, 4, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 4, 4, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 4, 4, 1024)   0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 4, 4, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 4, 4, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 4, 4, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 4, 4, 1024)   0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 4, 4, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 4, 4, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 4, 4, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 4, 4, 1024)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 2, 2, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 2, 2, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 2, 2, 2048)   0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 2, 2, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 2, 2, 2048)   0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 1, 2048)   0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fc6 (Dense)                     (None, 6)            12294       flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,600,006\n",
      "Trainable params: 23,546,886\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
